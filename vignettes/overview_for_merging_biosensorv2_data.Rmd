---
title: "overview_for_merging_biosensorv2_data"
author: "mcsaba"
date: "11/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries

```{r cars}
library(tidyverse)
library(pool)
library(tictoc)
library(DBI)
library(RPostgres)
library(digest)
library(furrr)
```

# Data

## Set variables

```{r pressure, echo=FALSE}
tic("Preparing data")
measurement_id = "000012113303__2021-09-03T16_45_31-Measurement_1"

results_dir = "/home/ubuntu/dcp_helper/data/results"

if ( dir.exists( file.path(results_dir,measurement_id) ) ) {
  print("start processing")
} else {
  print("needs to download")
  dir.create(file.path(results_dir,measurement_id))
  system( paste('aws s3 sync',
                paste0("s3://ascstore/flatfield/",measurement_id), 
                paste0("~/dcp_helper/data/results",measurement_id),
                '--exclude "*" --include "*.csv" --force-glacier-transfer') )
}
toc()
```
Listing results

```{r}
tic("Listing results")
file_list <- list.files(file.path(results_dir, measurement_id), pattern = "*Cells.csv", recursive=TRUE, full.names = TRUE)
# file_list <- Sys.glob(file.path(results_dir, measurement_id,"*","*Cells.csv"))
length(file_list)
toc()
```
```{r}
tic("Listing results")
results_list <- dir(file.path(results_dir, measurement_id), full.names = TRUE)
for (result in results_list) {
  
}
toc()
```
```{r message=FALSE, warning=FALSE}

compute_observations_checksum <- function(result_path, pattern = "*Cells.csv") {
  observation.list <- list.files(result_path, pattern = pattern, recursive = TRUE, full.names = TRUE)
  # print(result_path)
  # print(observation.list)
  
  return(paste(tools::md5sum(observation.list), collapse = '|'))
}

read_and_merge_observations <- function(result_path, pattern = "*Cells.csv"){
  
  observation.list <- list.files(result_path, pattern = pattern, recursive = TRUE, full.names = TRUE)
  # print(result_path)
  # print(observation.list)
  
  tbl_list <- c()
  
  i <- 1
  for (observation.file in observation.list) {
    tbl_list[[i]] <- read_csv(observation.file)
    i <- i + 1
  }
  
  reduced.observations <- Reduce(function(x, y) merge(x, y, all.x = TRUE),tbl_list) %>%
    select(-contains("Metadata"))
  colnames(reduced.observations) <- colnames(reduced.observations) %>%  
    str_replace(.,"projection","")
  
  return(reduced.observations %>% janitor::clean_names())
}

observation.checksum <- compute_observations_checksum(results_list[1])
reduced.observation <- read_and_merge_observations(results_list[1])

# tic("Read and merge all - for")
# for (result in results_list[1:1000]){
#   t_list <- read_and_merge_observations(file.path(results_dir, measurement_id, result))
# }
# toc()

# tic("Read and merge all - apply")
# for (result in results_list[1:200]){
#   t_list <- read_and_merge_observations(file.path(results_dir, measurement_id, result))
# }
# toc()
```

```{r}
host_db_base = "c9k2hfiwt5mi.us-east-2.rds.amazonaws.com"
```

# Database

## Database v1

### Connect

```{r}
dbname.v1 <- "biosensor"
con.v1 <- dbConnect(RPostgres::Postgres(), 
                 dbname = dbname.v1, 
                 host = paste(dbname.v1, host_db_base, sep = "."), 
                 port = 5432, 
                 user = "biosensor", 
                 password = "biosensor")

pool.v1 <- pool::dbPool(RPostgres::Postgres(),
                       host = paste(dbname.v1, host_db_base, sep = "."),
                       dbname = dbname.v1,
                       port = 5432,
                       user = "biosensor",
                       password = "biosensor")
```

### Overview

List tables and their columns

```{r}
table_list <- dbListTables(pool.v1)
for (table_name in table_list) {
  print(table_name)
  table <- tbl(pool.v1, table_name)
  # glimpse(table)
  print(colnames(table))
}
```
```{r}
measurement <- tbl(pool.v1, "measurement")
glimpse(measurement)
```

## Database v2

### Connect

```{r}
dbname.v2 <- "biosensorv2"
con.v2 <- dbConnect(RPostgres::Postgres(), 
                 dbname = dbname.v2, 
                 host = paste(dbname.v2, host_db_base, sep = "."), 
                 port = 5432, 
                 user = "biosensor", 
                 password = "biosensor")

pool.v2 <- pool::dbPool(RPostgres::Postgres(),
                       host = paste(dbname.v2, host_db_base, sep = "."),
                       dbname = dbname.v2,
                       port = 5432,
                       user = "biosensor",
                       password = "biosensor")
```

### Create tables

#### Measurement table
Creating measurement table
```{r}
# dbRemoveTable(con.v2, "measurement")
# dbCreateTable(con.v2, "measurement", new_measurement)
# dbExecute(con.v2, "TRUNCATE TABLE measurement")

table_list <- dbListTables(con.v2)
for (table_name in table_list) {
  print(table_name)
  table <- tbl(pool.v2, table_name)
  glimpse(table)
  # print(colnames(table))
}
```

Adding only new measurements

```{r}
# files <- list.files(file.path(results_dir, measurement_id), pattern = "ch1", full.names = TRUE) %>% paste0(., "/resolution1/", "measurement_ch2_Cells.csv")
results_list <- dir(file.path(results_dir, measurement_id), pattern = "ch1", full.names = TRUE)

tic("New measurement")
measurement <- tbl(pool.v2, "measurement")
existing_measurement <- measurement %>% dplyr::select(id_observation,id_observation_checksum) %>% distinct() %>% collect()

new_measurement = tibble(id_barcode = measurement_id %>% str_extract(pattern = "0000\\d+"),
         id_measurement = measurement_id,
         id_observation = results_list %>% str_extract(pattern = "0000\\d+__\\d+-\\d\\d-\\d+T\\d+_\\d+_\\d+-Measurement_\\d-sk\\d+-...-f..-ch\\d")
         ) %>%
    separate(id_observation, remove = FALSE, sep = "-", c("t1", "t2", "t3",  "measurement_no", "iteration_no", "well", "field", "channel")) %>% 
  select(-(t1:t3)) %>%
    mutate(measurement_no = str_extract(measurement_no, pattern = "\\d") %>% as.numeric(),
           iteration_no = str_extract(iteration_no, pattern = "\\d") %>% as.numeric()) %>%
    mutate(full_path = results_list) %>% rowwise() %>% 
    mutate(id_observation_checksum = compute_observations_checksum(full_path %>% as.character()) %>% as.character()) %>%
    anti_join(existing_measurement)
toc()

tic("Adding to database")
new_measurement %>%
    dbWriteTable(pool.v2, "measurement", ., append = TRUE)
toc()
```

#### Observation table

Creating observation table

```{r}
# dbCreateTable(con.v2, "observation", reduced.observation) 
# dbRemoveTable(con.v2, "observation") # completely deletes table schema
# dbExecute(con.v2, "TRUNCATE TABLE observation") # drops all rows from the table

# observation <- tbl(pool.v2, "observation")
# glimpse(observation)
```


```{r}
tic("adding observations")
new_measurement %>%
    unite("observation", contains("observation"), sep = "___") %>%
    mutate(data = furrr::future_map2(observation, 
                                     full_path, 
                                     ~ {read_and_merge_observations(.y) %>%
                                       mutate(observation = .x) %>%
                                       separate(observation, c("id_observation", "id_observation_checksum"), sep = "___", ) %>%
                                       dbWriteTable(pool.v2, "observation", ., append = TRUE)
                                    print(paste0("appended ", .y))
                  }
                                       ))
toc()
```

```{r}
# for (row_num in 1:nrow(new_measurement)){
# for (row_num in c(1,2)) {
#   row <- new_measurement[row_num,]
#   glimpse(row)
#   observation <- read_and_merge_observations(row[1,"full_path"] %>% as.character())
#   observation$id_observation <- row[1,"id_observation"] %>% as.character()
#   observation$id_observation_checksum <- compute_observations_checksum(row[1,"full_path"] %>% as.character())
#   glimpse(observation)
}
```


Check uploaded data

```{r}
observation <- tbl(pool.v2, "observation") %>% collect()
```

